<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2020-02-14">
  <title>Tools and Workflows for Data &amp; Metadata Management of Complex Experiments</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="slides.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="../reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title"><small>Tools and Workflows for Data &amp; Metadata Management of Complex Experiments </small></h1>
  <p class="subtitle"><tiny>Building a Foundation for Reproducible &amp; Collaborative Analysis in the Neurosciences</tiny></p>
  <p class="author">PhD Defense<br><br>Julia Sprenger<br><br>
<div style="margin-top:100px; position:relative; float:right;">
<img src="material/logos/fzj_mod.svg" class="left" width="250" /><img src="material/logos/rwth.svg" class="left" width="200" />
</div>
<p><br><br><br></p></p>
  <p class="date">14 Feb 2020</p>
</section>

<section><section id="introduction" class="titleslide slide level1"><h1>Introduction</h1></section><section id="neuroscientific-data---a-historic-example" class="slide level2">
<h2>Neuroscientific data - a historic example</h2>
<p>Image of a neuron, 1912</p>
<figure>
<img src="material/pyramidal_neuron_blue.png" style="width:70.0%" />
</figure>
<p><tiny>Figure adapted from <strong><em>Brain and spinal cord - manual for the study of the morphology and fibre tracts of the central nervous system (1912) Dr.med. Emil Villinger</em></strong></tiny></p>
</section><section id="but-what-does-this-tell-us" class="slide level2">
<h2>But what does this tell us?</h2>
<figure>
<img src="material/cortex_blue.png" style="width:70.0%" />
</figure>
<p><tiny>Figure adapted from <strong><em>Brain and spinal cord - manual for the study of the morphology and fibre tracts of the central nervous system (1912) Dr.med. Emil Villinger</em></strong></tiny></p>
</section><section id="additional-information-is-required" class="slide level2">
<h2>Additional information is required</h2>
<h3 id="recording-data">Recording data</h3>
<figure>
<img src="material/cortex_blue.png" class="left" style="width:60.0%" />
</figure>
<h3 id="metadata">Metadata</h3>
<ul>
<li class="fragment">brain area</li>
<li class="fragment">species</li>
<li class="fragment">date and time</li>
<li class="fragment">preparation technique</li>
<li class="fragment">visualization technique</li>
</ul>
<div class="fragment">
<p>Additional Metadata</p>
<ul>
<li class="fragment">experimenter</li>
<li class="fragment">temperature</li>
<li class="fragment">experimental notes, etc</li>
</ul>
</div>
</section><section id="neuroscience-today-brochier-et-al.-2018" class="slide level2">
<h2>Neuroscience today — <em>Brochier et al. 2018</em></h2>
<figure>
<img src="material/scidata_experiment_simple_ext.svg" style="width:90.0%" />
</figure>
<ul>
<li class="fragment">~ 5GB data per session (proprietary formats)</li>
<li class="fragment">~ 10k metadata values per session (various formats)</li>
</ul>
<div class="fragment">
<p>How can we handle such amounts of diverse data and metadata in a reproducible fashion?</p>
</div>
</section><section id="growing-importance-of-reproducibility-collaboration" class="slide level2">
<h2>Growing importance of reproducibility &amp; collaboration</h2>
<p>Fraction of publications relating to reproducibility and collaboration</p>
<figure>
<img src="material/trends.svg" style="width:60.0%" />
</figure>
<p>Figure based on data from <a href="https://www.ncbi.nlm.nih.gov/pubmed/">PubMed</a> using <a href="http://dan.corlan.net/medline-trend.html">Corlan (2004)</a>.</p>
</section><section id="challenges-for-modern-neuroscience" class="slide level2">
<h2>Challenges for modern neuroscience</h2>
<p>How to devise a general data and metadata management approach to ensure reproducibility of scientific findings?</p>
<ul>
<li>comprehensive metadata collection used by all collaboration members</li>
<li>standardized tools and formats for data and metadata for facilitated access</li>
<li>systematic organization of data and metadata aggregation process</li>
</ul>
</section><section id="overview-projects-publications" class="slide level2">
<h2>Overview — projects &amp; publications</h2>
<h3 id="data-publication-gin.g-node.orgintmultielectrode_grasp">Data publication (<a href="https://gin.g-node.org/INT/multielectrode_grasp">gin.g-node.org/INT/multielectrode_grasp</a>)</h3>
<blockquote>
<p><strong>Massively parallel multi-electrode recordings of macaque motor cortex during an instructed delayed reach-to-grasp task</strong><br> Brochier, T., Zehl, L., Hao, Y., Duret, M., <em>Sprenger, J.</em>, Denker, M., Grün, S., Riehle, A., 2018. Scientific Data 5, 180055. <a href="https://doi.org/10.1038/sdata.2018.55"></a></p>
</blockquote>
<h3 id="the-odmltables-package-github.cominm-6python-odmltables"><strong>The <em>odMLtables</em> package</strong> (<a href="https://github.com/inm-6/python-odmltables">github.com/inm-6/python-odmltables</a>)</h3>
<blockquote>
<p><strong>odMLtables: A user-friendly approach for managing metadata of neurophysiological experiments</strong> <br> <em>Sprenger, J.</em>, Zehl, L., Pick, J., Sonntag, M., Grewe, J., Wachtler, T., Grün, S., Denker, M., 2019. Front. Neuroinform. 13. <a href="https://doi.org/10.3389/fninf.2019.00062"></a></p>
</blockquote>
<h3 id="the-neo-package-github.comneuralensemblepython-neo"><strong>The <em>Neo</em> package</strong> (<a href="https://github.com/neuralensemble/python-neo">github.com/neuralensemble/python-neo</a>)</h3>
<ul>
<li>open source, community based Python package</li>
<li>standardized representation of electrophysiological data</li>
<li>interfacing to numerous proprietary and open source formats</li>
</ul>
</section></section>
<section><section id="metadata-management" class="titleslide slide level1"><h1>Metadata Management</h1></section><section id="open-metadata-markup-language-odml" class="slide level2">
<h2>open metadata Markup Language — odML</h2>
<figure>
<img src="material/odml.svg" style="width:70.0%" />
</figure>
<table>
<tr>
<td width="50%">
<ul>
<li>hierarchical metadata structure</li>
<li>generic objects</li>
<li>human &amp; machine readable</li>
</ul>
</td>
<td width="50%">
<ul>
<li>limited support for manual interaction</li>
<li>needs to be generated based <br> on metadata source files &amp; <em>manual notes</em>
</td>
</table></li>
</ul>
</section><section id="odmltables" class="slide level2">
<h2><img src="material/logos/odMLtables.png" class="left" style="width:10.0%" /> </t> odMLtables</h2>
<ul>
<li>conversion between tabular metadata structures and odML</li>
<li>generic spreadsheet software can be used for metadata collection</li>
<li>additional utility functions</li>
</ul>
<figure>
<img src="material/odmltables_usage_edit.svg" />
</figure>
</section><section id="graphical-user-interface" class="slide level2">
<h2>Graphical user interface</h2>
<figure>
<img src="material/Screenshot.png" class="left" style="width:50.0%" />
</figure>
<p><br><br></p>
<ul>
<li>easy access to the <em>odML</em> format <br> also for non-programmers</li>
<li>5 main functionalities available <br> as <code>wizard</code> dialogs for step-wise <br> configuration of odMLtables function</li>
<li>saving of configuration <br> settings for repeated use</li>
<li><code>wizards</code> are linked in <em>odML-ui</em> <br> for simplified accessiblity</li>
</ul>
</section></section>
<section><section id="handling-of-electrophysiological-data" class="titleslide slide level1"><h1>Handling of Electrophysiological Data</h1></section><section id="section" class="slide level2">
<h2><img src="material/logos/neo.svg" style="width:15.0%" /></h2>
<h3 id="neo-as-interface">Neo as interface</h3>
<figure>
<img src="material/neo_ios_and_tools_0.svg" style="width:42.0%" />
</figure>
</section><section id="section-1" class="slide level2">
<h2><img src="material/logos/neo.svg" style="width:15.0%" /></h2>
<figure>
<img src="material/neo_ios_and_tools.svg" class="right" style="width:45.0%" />
</figure>
<h3 id="neo-as-interface-1">Neo as interface</h3>
<p><br> <br></p>
<ul>
<li>interface to &gt;30 proprietary <br> &amp; open data formats</li>
<li>generic, standardized data <br> representation for electrophysiological <br> data</li>
<li>basis for applications and <br> scripts working on the data</li>
</ul>
</section><section id="section-2" class="slide level2">
<h2><img src="material/logos/neo.svg" style="width:15.0%" /></h2>
<h3 id="neo-as-standardized-data-representation">Neo as standardized data representation</h3>
<figure>
<img src="material/neo_schema.svg" class="right" style="width:50.0%" />
</figure>
<h3 id="features">Features</h3>
<ul>
<li>object oriented representation
<ul>
<li>data objects</li>
<li>container objects</li>
</ul></li>
<li>generic structure</li>
<li>support for custom metadata <br> via object names &amp; annotations</li>
<li>utility functions</li>
</ul>
<h3 id="recent-updates">Recent updates</h3>
<div style="float: left; margin-left: 55px;">
<ul>
<li>data related annotations (array annotations)</li>
<li>interface to additional formats (neuralynx, nest, blackrock, nix)</li>
<li>extended utilities (trial based slicing, resampling, ...)</li>
<li>simplification of object structure</li>
<li>performance improvements and refactoring</li>
</ul>
</div>
</section></section>
<section><section id="a-process-for-data-metadata-management" class="titleslide slide level1"><h1>A Process for Data &amp; Metadata Management</h1></section><section id="brochier-et-al.-2018-the-metadata-concept" class="slide level2">
<h2><em>Brochier et al. 2018</em> — The metadata concept</h2>
<figure>
<img src="material/scidata_odMLgeneration_diagram_0_ext_0.png" class="right" style="width:60.0%" />
</figure>
<h3 id="metadata-pipeline">Metadata pipeline</h3>
<ul>
<li>scripted aggregation of metadata
<ol type="1">
<li>generation of hierarchical <br> structure</li>
<li>enrichment with <br> metadata</li>
</ol></li>
</ul>
</section><section id="brochier-et-al.-2018-the-metadata-concept-1" class="slide level2">
<h2><em>Brochier et al. 2018</em> — The metadata concept</h2>
<figure>
<img src="material/scidata_odMLgeneration_diagram_0_ext_1.png" class="right" style="width:60.0%" />
</figure>
<h3 id="metadata-pipeline-1">Metadata pipeline</h3>
<ul>
<li>scripted aggregation of metadata
<ol type="1">
<li>generation of hierarchical <br> structure</li>
<li>enrichment with <br> metadata</li>
</ol></li>
</ul>
</section><section id="brochier-et-al.-2018-the-metadata-concept-2" class="slide level2">
<h2><em>Brochier et al. 2018</em> — The metadata concept</h2>
<figure>
<img src="material/scidata_odMLgeneration_diagram_0_ext_2.png" class="right" style="width:60.0%" />
</figure>
<h3 id="metadata-pipeline-2">Metadata pipeline</h3>
<ul>
<li>scripted aggregation of metadata
<ol type="1">
<li>generation of hierarchical <br> structure</li>
<li>enrichment with <br> metadata</li>
</ol></li>
<li>multiple, diverse source files</li>
</ul>
</section><section id="brochier-et-al.-2018-the-metadata-concept-3" class="slide level2">
<h2><em>Brochier et al. 2018</em> — The metadata concept</h2>
<figure>
<img src="material/scidata_odMLgeneration_diagram_ext.png" class="right" style="width:60.0%" />
</figure>
<h3 id="issues">Issues</h3>
<ul>
<li>structure and content are not <br> completely independent <br> → <em>convoluted generation</em> and <br> enrichment process</li>
<li><em>monolithic, linear compilation <br> script</em> <br> → obscured compilation <br> mechanism</li>
<li>requires manual inspection <br> of output for <em>status tracking</em></li>
<li><em>reuse</em> in other context requires <br> extended adjustments</li>
<li><em>detached</em> data and <br> metadata storage</li>
</ul>
</section><section id="improvement-of-the-metadata-concept" class="slide level2">
<h2>Improvement of the metadata concept</h2>
<h3 id="solutions-approach">Solutions approach</h3>
<figure>
<img src="material/scidata_odMLgeneration_diagram_ext.png" class="right" style="width:30.0%" />
</figure>
<p><strong>Combination of data and metadata in a single framework</strong> <br> → <em>Nix</em> format (<em>Neo</em>) captures data and metadata <br><br><br></p>
<p><strong>Systematic modularization of the compilation process</strong></p>
<ul>
<li>less maintenance</li>
<li>easier to reuse in other projects</li>
<li>improved tracking of compilation process</li>
<li>explicit dependencies</li>
</ul>
<p>→<em>Workflow management systems</em> (<em>snakemake</em>) for organization of data and metadata processes</p>
</section></section>
<section><section id="workflows" class="titleslide slide level1"><h1>Workflows</h1></section><section id="workflow-concept" class="slide level2">
<h2>Workflow concept</h2>
<figure>
<img src="material/workflow_concept_1.svg" class="left" style="width:30.0%" />
</figure>
<ul>
<li>modular processing steps (rules)</li>
<li>defined input and output files</li>
</ul>
</section><section id="workflow-concept-1" class="slide level2">
<h2>Workflow concept</h2>
<figure>
<img src="material/workflow_concept_2.svg" class="left" style="width:30.0%" />
</figure>
<ul>
<li>modular processing steps (rules)</li>
<li>defined input and output files</li>
<li>change propagation</li>
<li>relation tracking &amp; visualization</li>
</ul>
</section><section id="workflows-in-science" class="slide level2">
<h2>Workflows in science</h2>
<h3 id="from-data-recording-to-reproducible-publications-using-workflows">From data recording to reproducible publications using workflows</h3>
<figure>
<img src="material/global_picture_workflow_0.png" class="left" style="width:45.0%" />
</figure>
<ul>
<li>visualization of dependencies <br> and execution status</li>
<li>portable and extendable via <br> via modular approach</li>
<li>combined data &amp; metadata packaging <br> using <em>Nix</em></li>
<li>enables automatized provenance <br> tracking on file level</li>
</ul>
</section><section id="workflows-in-science-1" class="slide level2">
<h2>Workflows in science</h2>
<h3 id="from-data-recording-to-reproducible-publications-using-workflows-1">From data recording to reproducible publications using workflows</h3>
<figure>
<img src="material/global_picture_workflow_1.png" class="left" style="width:45.0%" />
</figure>
<ul>
<li>visualization of dependencies <br> and execution status</li>
<li>portable and extendable via <br> via modular approach</li>
<li>combined data &amp; metadata packaging <br> using <em>Nix</em></li>
<li>enables automatized provenance <br> tracking on file level</li>
</ul>
</section><section id="workflows-in-science-2" class="slide level2">
<h2>Workflows in science</h2>
<h3 id="from-data-recording-to-reproducible-publications-using-workflows-2">From data recording to reproducible publications using workflows</h3>
<figure>
<img src="material/global_picture_workflow_2.png" class="left" style="width:45.0%" />
</figure>
<ul>
<li>visualization of dependencies <br> and execution status</li>
<li>portable and extendable via <br> via modular approach</li>
<li>combined data &amp; metadata packaging <br> using <em>Nix</em></li>
<li>enables automatized provenance <br> tracking on file level</li>
</ul>
</section><section id="workflow-implementation" class="slide level2">
<h2>Workflow implementation</h2>
<p>Visualization of snakemake rules <img src="material/logos/snakemake.svg" class="left" style="width:4.0%" /> <br><br> <img src="material/rulegraph_colored.svg" class="left" style="width:45.0%" /></p>
<h3 id="advantages">Advantages</h3>
<ul>
<li>categorization of rules based <br> on application level</li>
<li>separation of <em>generic</em> and <br> project specific rules</li>
<li>parallelization capabilities</li>
<li>explicit <em>dependency description</em> <br> and visualization</li>
<li>flexibly <em>extendable</em></li>
<li>no separation of metadata <br> structure &amp; content</li>
<li><em>automatic propagation</em> of changes</li>
</ul>
</section></section>
<section><section id="summary-outlook" class="titleslide slide level1"><h1>Summary &amp; Outlook</h1></section><section id="summary" class="slide level2">
<h2>Summary</h2>
<p>We provide a solution for reproducible data and metadata collection and processing based on open source tools.</p>
<ul>
<li>Based on our data publication <em>Brochier et al. 2018</em> we identified deficiencies and issues in designing a scalable, portable, generic, rigorous workflow for data and metadata acquisition. We designed solutions which close these gaps:</li>
<li>By providing <em>odMLtables</em> we facilitate the metadata collection in laboratory environments and make the odML standard available to non-programmers, while conserving existing interfaces (spreadsheet software).</li>
<li>We contributed major functionality to the <em>Neo</em> package that was lacking in building our acquisition workflow: support for additional formats, functionality for data manipulations, direct links between data and metadata.</li>
<li>We devise a portable, modular approach for reproducible data and metadata management based on <em>workflow management systems</em> that scales from experimental data acquisition to data and analysis publication. The approach is flexibly adaptable and can be implemented based on generic modules.</li>
</ul>
</section><section id="outlook" class="slide level2">
<h2>Outlook</h2>
<h3 id="odmltables-1">odMLtables</h3>
<div style="margin-top:0px;margin-bottom:0px; position:relative; float:left;">
<ul>
<li>integration of <em>odMLtables</em> functionality into <em>odML</em> package
</div>
<br><br></li>
</ul>
<h3 id="neo">Neo</h3>
<div style="margin-top:0px;margin-bottom:0px; position:relative; float:left;">
<ul>
<li>extended support of formats and improve user friendliness &amp; performance
</div>
<br><br></li>
</ul>
<h3 id="workflows-1">Workflows</h3>
<ul>
<li>application to other collaborative projects</li>
<li>integration of <strong>systematic version control</strong> mechanisms in workflow (pull-requests)</li>
<li>support for larger frameworks, e.g. HBP <strong>knowledgegraph</strong></li>
<li>extension to capture <strong>provenance</strong> information</li>
<li><strong>parallelization</strong> using cluster computing</li>
<li>initialization of a community based <strong>collection of general rules</strong> and standardized preprocessing steps, e.g. format conversions and signal quality checks</li>
<li>embedding in <strong>continuous integration</strong> system
<ul>
<li>automated execution upon data or metadata update</li>
<li>immediate quality control of data (artifact detection)</li>
</ul></li>
</ul>
</section><section id="thank-you" class="slide level2">
<h2>Thank you!</h2>
<p><img src="material/logos/snakemake.svg" height="80" /> <img src="material/logos/odml.png" height="80" /> <img src="material/logos/neo.svg" height="80" /> <img src="material/logos/elephant.png" height="80" /> <img src="material/logos/odMLtables.png" height="80" /> <img src="material/logos/nix_logo.png" height="80" /> <img src="material/logos/gin.svg" height="80" /> <img src="material/logos/python.svg" height="80" /> <img src="material/logos/matplotlib_logo.svg" height="80" /> <img src="material/logos/jupyter.png" height="80" /></p>
<figure>
<img src="material/INM-6.jpg" style="width:100.0%" />
</figure>
</section></section>
    </div>
  </div>

  <script src="../reveal.js/lib/js/head.min.js"></script>
  <script src="../reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({

        // Optional reveal.js plugins
        dependencies: [
          { src: '../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '../reveal.js/plugin/zoom-js/zoom.js', async: true },
              { src: '../reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
